# G.A.I.A.

## Overview
G.A.I.A. (Generative Audio via Interaction with Ambient) is an ambient synth that takes its data both from the environment and from the user interaction.
G.A.I.A. generates ambient sound which varies with respect to ambient parameters' changes and user interaction, and generates also a visual associated with these changes.

---

## Project Structure

- Arduino: collects real world data (temperature, humidity and lightness) thanks to sensors;
- SuperCollider: audio synthesys;
- JUCE: applies of effects to the sound generated by Supercollider and reproduces it;
- Visual Studio 2022: used to run JUCE projects;
- Processing: visual synthesys;
- [VCable]: (https://vb-audio.com/Cable/?gad_source=1&gad_campaignid=266017394&gbraid=0AAAAADjKyE4mWRWFgCjUTKuyoref436kI&gclid=CjwKCAjw_pDBBhBMEiwAmY02NrUUqg9d52OqmtTlAULf3YHqZgk615ma1muYRhYF2BlX35O2aDD2JhoCdJwQAvD_BwE) / BlackHole: tool that depends on the OS that is running on the user machine, allows the audio transfer from SuperCollider to JUCE;
- OSC: protocol that sends the data collected by Arduino to SuperCollider and Processing.
- G.A.I.A. Custom Case: 3D printed custom case which allows better interaction with ambient parameters.

---

## Modules and Files

1. **GAIA_Arduino**: reads real-time environmental data from a DHT22 sensor (temperature and humidity) and a photoresistor (light). The collected values are transmitted over a local network using the OSC (Open Sound Control) protocol to two different applications: SuperCollider and Processing —each on a separate UDP port. Additionally, the program generates random time-based events (bars and musical notes), which are sent to SuperCollider to influence sound generation. This creates an interactive audiovisual system that responds dynamically to environmental conditions. 

2. **GAIA.scd**: creates a generative audio system that reacts to real-time environmental data received via OSC from an Arduino board or simulated inputs. The system responds to temperature, humidity and light levels, as well as rhythmic triggers, to control a synth called GAIA.
The script includes multiple sections:
    - Setup and Controls – Initializes the SuperCollider server and configures audio and OSC settings.
    - OSC Reception – Defines how incoming sensor data and triggers are received and mapped to synthesis parameters.
    - Print Routine – Continuously prints formatted sensor and control values for debugging and monitoring.
    - Synth Definition – The GAIA SynthDef generates harmonically rich textures using bass lines, chords, and melodic notes. Each       element is modulated by incoming sensor values, enabling dynamic, environment-driven soundscapes.

Execution Modes:
    - Arduino Mode: Receives real sensor data and triggers from an Arduino via OSC.
    - Simulator Mode: Generates random sensor values and triggers for testing without hardware, and sends them to Processing and JUCE over OSC.

***Focus on the GAIA Synth***:
The GAIA synth is designed as a dynamic, ambient sound generator that reacts expressively to environmental input. It blends three key sound layers—bass, chords, and melodic notes—each modulated by sensor data received via OSC.
Structure and Features:
- Bass Layer:
    Based on a step-sequenced selection of MIDI notes, the bass is built from two detuned LFPar oscillators. The modulation depth is influenced by light intensity, creating evolving low-frequency movement.

- Chord Layer:
    A selection of 3-note chords is triggered by a bar-level pulse. The harmonic content (number of partials) is controlled by light, while humidity influences the chord envelope's duration. Chords are synthesized using Blip oscillators, contributing a shimmering, rich harmonic layer.

- Melodic Layer:
    Short notes are generated using SinOsc and triggered independently of the chord progression. The note value, duration, and trigger are all received via OSC, allowing fine-grained control—ideal for melodic interaction.

- Modulations:
    Temperature adjusts the LFO speed for amplitude modulation and sets the tonal center—essentially the root note around which harmonies are constructed.
    Humidity modulates envelope durations, affecting the sustain of the chords.
    Light modulates both the number of harmonics and the detuning of bass oscillators, enriching the timbral complexity.

- Output:
    The final signal is sent in 6 separate channels (3 couple of R/L signals) for further processing.

3. **CMLS-PROJECT-JUCE**



4. **GAIA_Processing**
This Processing sketch creates a dynamic particle system that reacts in real-time to environmental sensor data received via OSC messages from Arduino. The data includes temperature, humidity, and light levels, which are mapped to control the color, lifespan, and acceleration of particles on screen. By continuously receiving and normalizing the sensor values, the sketch adjusts the particle behavior and appearance, producing an evolving and interactive visual representation of the surrounding environment.

- GAIA_processing.pde:
This part of the code sets up the OSC receiver to listen for messages on a specific UDP port. It translates the raw integer sensor values into normalized floats between zero and one, suitable for controlling visual parameters. This segment also initializes the particle system with a set number of particles and continuously updates the system each frame based on the latest sensor readings. Additionally, it includes debug prints to track incoming OSC messages and the mapped values, helping verify that data flows correctly from the sensors into the visual system.

- particle.pde:
This part defines the Particle class, representing individual particles within the system. Each particle has properties like position, velocity, acceleration, radius, lifespan, and a hue value that determines its color. Particles respond to forces by adjusting their acceleration and velocity, allowing for natural movement behaviors. As time progresses, their lifespan gradually decreases until they “die” and get removed from the system. This class also handles rendering each particle with colors based on the hue, which is linked to the light sensor value, adding a direct visual correlation between environmental data and particle appearance.

- particleSys.pde:
This section implements the ParticleSystem class, which manages a collection of Particle instances. This class controls how new particles are born, how they move, and how they are removed when expired. The birth rate is linked to humidity levels, meaning wetter conditions produce more particles. The acceleration forces applied to particles are scaled by temperature levels, influencing their speed and movement dynamics. The particle colors are also adjusted according to lightness. The system ensures a maximum number of particles to maintain performance and applies small random forces each frame to create organic, lively motion. The combination of these controls provides a rich and nuanced visual environment that mirrors the sensor inputs in an engaging and artistic way.

---

## Technologies Used
- **Interaction System**: Arduino MKR WiFi 1010, DHT22 temperature and humidity sensor, LDR photoresistor, OSC protocol, Virtual Audio Cable
- **Audio Syntesys**: Supercollider, Juce
- **Visual Syntesys**: Processing

---

## Credits
- Marco Porcella marco.porcella@mail.polimi.it
- Filippo Longhi filippo1.longhi@mail.polimi.it
- Andrea Crisafulli andrea.crisafulli@mail.polimi.it
- Giacomo De Toni giacomo1.detoni@mail.polimi.it

This project was developed as part of the Computer Music: Languages and Systems course at Politecnico di Milano (2024/2025).
 
